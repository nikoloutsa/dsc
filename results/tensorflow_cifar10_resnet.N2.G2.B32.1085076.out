Start at Sat Jan 30 21:40:37 EET 2021
CUDA_VISIBLE_DEVICES: 0,1
Running on hosts: gpu[08-09]
Running on 2 nodes.
Running 1 tasks per node
Job id is 1085076
srun gpu08 {"cluster": {"worker": ["gpu08-ib:5555","gpu09-ib:5555"]}, "task": {"type": "worker", "index": 0} }
srun gpu09 {"cluster": {"worker": ["gpu08-ib:5555","gpu09-ib:5555"]}, "task": {"type": "worker", "index": 1} }
0: Number of devices: 2
0: 2021-01-30 21:41:02,966 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:02,978 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:02,987 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:02,993 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: Number of devices: 2
0: 2021-01-30 21:41:02,997 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,007 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,011 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,015 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,020 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,025 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,048 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,054 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,074 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,084 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,093 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,099 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,100 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,110 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,119 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:03,126 INFO Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: Epoch 1/3
0: 2021-01-30 21:41:09,810 WARNING From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: Epoch 1/3
0: 2021-01-30 21:41:09,834 WARNING From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: 2021-01-30 21:41:18,751 INFO Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:18,917 INFO Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:29,764 INFO Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 2021-01-30 21:41:30,716 INFO Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1
0: 1563/1563 - 160s - loss: 3.0299 - accuracy: 0.2301 - val_loss: 4.9734 - val_accuracy: 0.3071
0: 1563/1563 - 167s - loss: 3.2293 - accuracy: 0.2305 - val_loss: 20.4937 - val_accuracy: 0.3061
0: Epoch 2/3
0: 1563/1563 - 156s - loss: 2.5755 - accuracy: 0.3005 - val_loss: 7.9158 - val_accuracy: 0.3714
0: Epoch 2/3
0: 1563/1563 - 163s - loss: 2.5663 - accuracy: 0.3033 - val_loss: 13.0184 - val_accuracy: 0.3622
0: Epoch 3/3
0: 1563/1563 - 156s - loss: 2.2851 - accuracy: 0.3436 - val_loss: 10.9834 - val_accuracy: 0.3913
0: Steps per epoch: 1563
0: Validation steps per epoch: 313
0: Best validation accuracy: 0.391
0: Average time per epoch: 169.595 s
0: --- 519.8612740039825 seconds ---
0: Epoch 3/3
0: 1563/1563 - 164s - loss: 2.4835 - accuracy: 0.3056 - val_loss: 4.3713 - val_accuracy: 0.3478
0: Steps per epoch: 1563
0: Validation steps per epoch: 313
0: Best validation accuracy: 0.362
0: Average time per epoch: 176.791 s
0: --- 541.3949172496796 seconds ---
ELAPSED: 568 seconds
End at Sat Jan 30 21:50:05 EET 2021
