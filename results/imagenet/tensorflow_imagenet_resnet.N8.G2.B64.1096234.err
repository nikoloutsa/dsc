srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
srun: Warning: can't run 1 processes on 8 nodes, setting nnodes to 1
0: 2021-02-16 21:46:14.832802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:14.921261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:14.936563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:14.951186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:14.974603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:14.977272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:18.857521: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:18.857650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.261016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.261654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.261628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.262564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.263447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.263211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.263647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.263754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
0: 2021-02-16 21:46:29.318801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.320156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.320180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.325775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.325678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.327132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.327160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.327013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.327041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.328897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.329211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.330265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.330293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.330568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.330596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.331350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.331628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.332970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.332997: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.333876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.333924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.334716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.336040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:29.336068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:29.583486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.584072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.583667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.583802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.584105: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.584180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.584295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.584535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:29.710413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.710413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.712061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.712730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.713168: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.713677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.713971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.716406: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:29.938724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.939110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.939074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.939376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.939389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.939645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.939933: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:29.941009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:30.443802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.443888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.444083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.444819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.444838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.446067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.454623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.457993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.499598: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.499749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 0: 2021-02-16 21:46:30.500300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-16 21:46:30.500509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 0: 2021-02-16 21:46:30.500389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-16 21:46:30.500289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.500510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.501282: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.742331: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.745989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.745547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.745729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.747131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.747630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.748311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 2021-02-16 21:46:30.748905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.751390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.750972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.751040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.751977: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 2021-02-16 21:46:30.751613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 2021-02-16 21:46:30.751780: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 2021-02-16 21:46:30.753814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.754341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 2021-02-16 21:46:30.755909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.756541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.757488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.758321: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 2021-02-16 21:46:30.760415: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599930000 Hz
0: 2021-02-16 21:46:30.761958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.762712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.762971: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
0: 0: 2021-02-16 21:46:30.763040: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600130000 Hz
2021-02-16 21:46:30.763109: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599975000 Hz
0: 0: 2021-02-16 21:46:30.763678: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
0: 2021-02-16 21:46:30.763863: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56e97e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.764231: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600075000 Hz
0: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-16 21:46:30.763884: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.765619: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599905000 Hz
0: 2021-02-16 21:46:30.766024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a9890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.766042: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.766420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4268710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.766441: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.767756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x46b4880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.767776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.768885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x531fa10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.768905: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.769645: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600165000 Hz
0: 2021-02-16 21:46:30.773049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d42890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.773067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.778232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600005000 Hz
0: 2021-02-16 21:46:30.779361: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600095000 Hz
0: 2021-02-16 21:46:30.781963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4296a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.781987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.782846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c41a30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.782872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0: 2021-02-16 21:46:30.955274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57559e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.955316: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.955330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.958124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.958503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x538bbf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.958547: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.958561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.959750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4720a50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.959793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 0: 2021-02-16 21:46:30.959806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
2021-02-16 21:46:30.959342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5715a50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.959380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.959393: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.959538: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42d48d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.959565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.959572: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.960400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.960453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.960494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:30.960519: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:30.960543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:30.960567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.960590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.960619: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.961050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4daea50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.961095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.961109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.961571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.962104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 0: 2021-02-16 21:46:30.962210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
2021-02-16 21:46:30.962632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: 0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: 0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.962808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.962840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.962866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:30.962880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:30.962892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:30.962906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.962918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.962931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.963802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.964255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.964286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.964906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: 0: 2021-02-16 21:46:30.964312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: 0: 2021-02-16 21:46:30.964326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 0: 0: 2021-02-16 21:46:30.964522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
2021-02-16 21:46:30.964339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-16 21:46:30.964958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: 2021-02-16 21:46:30.964352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.964999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 0: 2021-02-16 21:46:30.964365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-16 21:46:30.965025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 0: 2021-02-16 21:46:30.964573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.964378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-16 21:46:30.965048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:30.964617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:30.965072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.964645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:30.965098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.964671: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:30.965124: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.964696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.964722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.964749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 0: 2021-02-16 21:46:30.966259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.966075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
2021-02-16 21:46:30.966292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:30.966126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.966165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:30.966194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:30.966220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:30.966245: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:30.966273: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:30.966300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:30.967643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.967677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.968936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.969054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.971171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.971279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.974088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.974120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.973644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:30.973684: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:30.974156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4cadc10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.974196: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.974210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.975158: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4302bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
0: 2021-02-16 21:46:30.975199: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:30.975213: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
0: 2021-02-16 21:46:31.003093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.003435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.005370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.005422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.005461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:31.005490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:31.005515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:31.005540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:31.005565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.005590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:31.005764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.005815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.005853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:31.005878: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:31.005903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:31.005927: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:31.005959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.006016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:31.012109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:31.012184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.014544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:31.014664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.927077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.927113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.927124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.927129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.928622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.928656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.928666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.928671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.931034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.932227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.932265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.932298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.932305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.932575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.932908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.933717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.933756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.933768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.933772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.933325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.933359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.933397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.933405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.934522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.936429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.937782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.937546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.938294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.938641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.938676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.938687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.938692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.939656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.939349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.939457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.940535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.940570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.940598: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:31.940612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:31.940625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:31.940638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 0: 2021-02-16 21:46:31.940650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.940576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
2021-02-16 21:46:31.940672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.941811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.941845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.941871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:31.941885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:31.941897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:31.941911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:31.941923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.941937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:31.942593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.944458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.945696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: 0: 0: 2021-02-16 21:46:31.945433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
2021-02-16 21:46:31.945236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: 0: 0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
2021-02-16 21:46:31.945487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: 0: 2021-02-16 21:46:31.945496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.945502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.945507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.945692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.946859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 0: 2021-02-16 21:46:31.946488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
2021-02-16 21:46:31.946893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 0: 2021-02-16 21:46:31.946921: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-16 21:46:31.946523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 0: 0: 2021-02-16 21:46:31.946550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-16 21:46:31.946934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-16 21:46:31.946670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 0: 2021-02-16 21:46:31.946946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-16 21:46:31.946566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 0: 2021-02-16 21:46:31.946723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.946959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:31.946579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-16 21:46:31.946733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 0: 2021-02-16 21:46:31.946971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.946592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-16 21:46:31.946739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 0: 0: 2021-02-16 21:46:31.946604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-16 21:46:31.946984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-16 21:46:31.946744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.946618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:31.946970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.947003: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.947029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:31.947044: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:31.947058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:31.947072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:31.947086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.947100: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:31.949214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.950478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.950381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: 0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
2021-02-16 21:46:31.950484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:5/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:31.951598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:31.951648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.951656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.951662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.951666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.951346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:31.951401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.951411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.951418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.951423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 0: 2021-02-16 21:46:31.951632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
2021-02-16 21:46:31.951761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:5/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 0: 2021-02-16 21:46:31.951804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 0: 2021-02-16 21:46:31.951858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-16 21:46:31.951667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:31.951868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 0: 2021-02-16 21:46:31.951874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
2021-02-16 21:46:31.951693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 0: 2021-02-16 21:46:31.951878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
2021-02-16 21:46:31.951707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:31.951719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:31.951732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:31.951744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:31.951757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:31.955336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.955002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:6/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.955602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:7/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.956552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.956168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:6/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.956375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:31.956422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:31.956430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:31.956435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:31.956440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:31.956821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:7/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.959976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:4/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.961131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:4/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:31.965267: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:31.966140: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu23-ib:5555
0: 2021-02-16 21:46:31.966278: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:31.967124: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu28-ib:5555
0: 2021-02-16 21:46:31.970550: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:31.971222: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:31.971387: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu29-ib:5555
0: 2021-02-16 21:46:31.972100: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu24-ib:5555
0: 2021-02-16 21:46:31.971664: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:31.972960: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu30-ib:5555
0: 2021-02-16 21:46:31.980694: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:31.982251: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu27-ib:5555
0: 2021-02-16 21:46:32.360419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:32.360456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:32.360490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:32.360498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:32.362917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:32.362951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:32.362984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:32.362991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:32.364567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.366552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.367016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.369002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.372895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:32.374077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:32.374111: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:32.374134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:32.374149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:32.374162: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:32.374175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:32.374188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:32.374202: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:32.377786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
0: pciBusID: 0000:04:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:32.378764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:32.378816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:32.378825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:32.378831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:32.378836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:32.380087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
0: pciBusID: 0000:82:00.0 name: Tesla K40m computeCapability: 3.5
0: coreClock: 0.8755GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
0: 2021-02-16 21:46:32.380140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
0: 2021-02-16 21:46:32.380181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:46:32.380209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
0: 2021-02-16 21:46:32.380236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
0: 2021-02-16 21:46:32.380262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
0: 2021-02-16 21:46:32.380288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
0: 2021-02-16 21:46:32.380315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:46:32.382508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:2/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.383756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:2/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.389189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
0: 2021-02-16 21:46:32.389242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
0: 2021-02-16 21:46:32.389251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
0: 2021-02-16 21:46:32.389256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
0: 2021-02-16 21:46:32.389261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
0: 2021-02-16 21:46:32.392878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:3/device:GPU:0 with 10622 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.394066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:3/device:GPU:1 with 10622 MB memory) -> physical GPU (device: 1, name: Tesla K40m, pci bus id: 0000:82:00.0, compute capability: 3.5)
0: 2021-02-16 21:46:32.399944: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:32.401602: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu25-ib:5555
0: 2021-02-16 21:46:32.410235: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> gpu23-ib:5555, 1 -> gpu24-ib:5555, 2 -> gpu25-ib:5555, 3 -> gpu26-ib:5555, 4 -> gpu27-ib:5555, 5 -> gpu28-ib:5555, 6 -> gpu29-ib:5555, 7 -> gpu30-ib:5555}
0: 2021-02-16 21:46:32.411352: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://gpu26-ib:5555
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 0, environment = None, rpc_layer = 'grpc'
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:0/device:GPU:0', '/job:worker/task:0/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 0, num_workers = 8, local_devices = ('/job:worker/task:0/device:GPU:0', '/job:worker/task:0/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:0/device:GPU:0', '/job:worker/task:0/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 0, num_workers = 8, local_devices = ('/job:worker/task:0/device:GPU:0', '/job:worker/task:0/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 2, environment = None, rpc_layer = 'grpc'
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 5, environment = None, rpc_layer = 'grpc'
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 3, environment = None, rpc_layer = 'grpc'
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 1, environment = None, rpc_layer = 'grpc'
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 7, environment = None, rpc_layer = 'grpc'
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 6, environment = None, rpc_layer = 'grpc'
0: INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 4, environment = None, rpc_layer = 'grpc'
0: 0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:5/device:GPU:0', '/job:worker/task:5/device:GPU:1')
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:2/device:GPU:0', '/job:worker/task:2/device:GPU:1')
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an "evaluator" task exists in the cluster.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 5, num_workers = 8, local_devices = ('/job:worker/task:5/device:GPU:0', '/job:worker/task:5/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:3/device:GPU:0', '/job:worker/task:3/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 2, num_workers = 8, local_devices = ('/job:worker/task:2/device:GPU:0', '/job:worker/task:2/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:2/device:GPU:0', '/job:worker/task:2/device:GPU:1')
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:7/device:GPU:0', '/job:worker/task:7/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 3, num_workers = 8, local_devices = ('/job:worker/task:3/device:GPU:0', '/job:worker/task:3/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1/device:GPU:0', '/job:worker/task:1/device:GPU:1')
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:5/device:GPU:0', '/job:worker/task:5/device:GPU:1')
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:6/device:GPU:0', '/job:worker/task:6/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 1, num_workers = 8, local_devices = ('/job:worker/task:1/device:GPU:0', '/job:worker/task:1/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:4/device:GPU:0', '/job:worker/task:4/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 5, num_workers = 8, local_devices = ('/job:worker/task:5/device:GPU:0', '/job:worker/task:5/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 7, num_workers = 8, local_devices = ('/job:worker/task:7/device:GPU:0', '/job:worker/task:7/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:3/device:GPU:0', '/job:worker/task:3/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 2, num_workers = 8, local_devices = ('/job:worker/task:2/device:GPU:0', '/job:worker/task:2/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: 0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 6, num_workers = 8, local_devices = ('/job:worker/task:6/device:GPU:0', '/job:worker/task:6/device:GPU:1'), communication = CollectiveCommunication.AUTO
INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1/device:GPU:0', '/job:worker/task:1/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 4, num_workers = 8, local_devices = ('/job:worker/task:4/device:GPU:0', '/job:worker/task:4/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:6/device:GPU:0', '/job:worker/task:6/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 3, num_workers = 8, local_devices = ('/job:worker/task:3/device:GPU:0', '/job:worker/task:3/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:7/device:GPU:0', '/job:worker/task:7/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 1, num_workers = 8, local_devices = ('/job:worker/task:1/device:GPU:0', '/job:worker/task:1/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:4/device:GPU:0', '/job:worker/task:4/device:GPU:1')
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 7, num_workers = 8, local_devices = ('/job:worker/task:7/device:GPU:0', '/job:worker/task:7/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 6, num_workers = 8, local_devices = ('/job:worker/task:6/device:GPU:0', '/job:worker/task:6/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['gpu23-ib:5555', 'gpu24-ib:5555', 'gpu25-ib:5555', 'gpu26-ib:5555', 'gpu27-ib:5555', 'gpu28-ib:5555', 'gpu29-ib:5555', 'gpu30-ib:5555']}, task_type = 'worker', task_id = 4, num_workers = 8, local_devices = ('/job:worker/task:4/device:GPU:0', '/job:worker/task:4/device:GPU:1'), communication = CollectiveCommunication.AUTO
0: 2021-02-16 21:48:05.739045: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.036668: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.272135: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.314028: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.399353: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.500087: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.613010: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12936"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 21:48:06.764586: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_12607"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: 0: Use `tf.data.Iterator.get_next_as_optional()` instead.
WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: WARNING:tensorflow:From /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
0: Instructions for updating:
0: Use `tf.data.Iterator.get_next_as_optional()` instead.
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: INFO:tensorflow:Collective batch_all_reduce: 214 all-reduces, num_devices = 2, group_size = 16, communication_hint = AUTO, num_packs = 1
0: 2021-02-16 21:48:40.367309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:40.482145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:40.508450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:40.513554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:41.444112: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:41.466959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:41.567669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:48:41.873374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
0: 2021-02-16 21:49:08.521338: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.521605: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.522413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.522831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.523029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.523338: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.527333: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 21:49:08.527621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
0: 2021-02-16 22:35:34.250508: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:34.850702: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:34.854665: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:34.988284: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:35.109562: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_49380"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:35.189025: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:35.308574: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: 2021-02-16 22:35:35.764113: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
0: op: "FlatMapDataset"
0: input: "TensorDataset/_1"
0: attr {
0:   key: "Targuments"
0:   value {
0:     list {
0:     }
0:   }
0: }
0: attr {
0:   key: "f"
0:   value {
0:     func {
0:       name: "__inference_Dataset_flat_map_flat_map_fn_48831"
0:     }
0:   }
0: }
0: attr {
0:   key: "output_shapes"
0:   value {
0:     list {
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:       shape {
0:         dim {
0:           size: -1
0:         }
0:         dim {
0:           size: -1
0:         }
0:       }
0:     }
0:   }
0: }
0: attr {
0:   key: "output_types"
0:   value {
0:     list {
0:       type: DT_FLOAT
0:       type: DT_FLOAT
0:     }
0:  
0:  }
0: }
0: . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: /apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
0:   warnings.warn(str(msg))
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.
0: 2021-02-16 23:01:59.933009: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_2/else/_19/cond_2/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce_1/CollectiveReduce/_46]]
0: 2021-02-16 23:01:59.933129: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_2/else/_19/cond_2/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce_1/CollectiveReduce/_46]]
0: 2021-02-16 23:01:59.934431: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[GroupCrossDeviceControlEdges_0/Identity_5/_61]]
0: 2021-02-16 23:01:59.934530: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[GroupCrossDeviceControlEdges_0/Identity_5/_61]]
0: 2021-02-16 23:02:00.002583: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.002680: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.003424: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.003544: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.003222: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce/CollectiveReduce/_44]]
0: 2021-02-16 23:02:00.003375: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce/CollectiveReduce/_44]]
0: 2021-02-16 23:02:00.003555: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce/CollectiveReduce/_44]]
0: 2021-02-16 23:02:00.003671: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce/CollectiveReduce/_44]]
0: 2021-02-16 23:02:00.004476: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_2/else/_19/cond_2/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce_1/CollectiveReduce/_46]]
0: 2021-02-16 23:02:00.004595: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_2/else/_19/cond_2/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce_1/CollectiveReduce/_46]]
0: 2021-02-16 23:02:00.005263: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.005371: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.004625: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 2021-02-16 23:02:00.004739: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 2021-02-16 23:02:00.005523: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.005547: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[GroupCrossDeviceControlEdges_1/Identity_6/_73]]
0: 2021-02-16 23:02:00.005631: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.005637: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[GroupCrossDeviceControlEdges_1/Identity_6/_73]]
0: 2021-02-16 23:02:00.005300: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.005406: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.005570: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 	 [[div_no_nan_1/allreduce_1/CollectiveReduce/_46]]
0: 2021-02-16 23:02:00.005714: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 0: 2021-02-16 23:02:00.006158: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[div_no_nan_1/allreduce_1/CollectiveReduce/_46]]
0: 	 [[{{node cond_2/else/_19/cond_2/IteratorGetNext}}]]
0: 2021-02-16 23:02:00.006281: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Out of range: [_Derived_]End of sequence
0: 	 [[{{node cond_2/else/_19/cond_2/IteratorGetNext}}]]
0: 2021-02-16 23:02:00.006886: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.006986: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.009060: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Cancelled: RPC Request was cancelled
0: 2021-02-16 23:02:00.009112: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Cancelled: RPC Request was cancelled
0: Traceback (most recent call last):
0:   File "train.tensorflow.distributed.py", line 131, in <module>
0:     main()
0:   File "train.tensorflow.distributed.py", line 108, in main
0:     hist = model.fit(train_dataset,
0: 0: Traceback (most recent call last):
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
0: 0:   File "train.tensorflow.distributed.py", line 131, in <module>
    return dc.run_distribute_coordinator(
0: 0:     main()
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
0: 0:   File "train.tensorflow.distributed.py", line 108, in main
    return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
0: 0:     hist = model.fit(train_dataset,
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
    return worker_fn(strategy)
0: 0:     return dc.run_distribute_coordinator(
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
    lambda _: method(self, *args, **kw0: 
    return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
args),
0: 0:     return worker_fn(strategy)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
    callbacks.on_epoch_end(epoch, epoch_logs)
0: 0:     lambda _: method(self, *args, **kw  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end

0:     callback.on_epoch_end(epoch, logs)
0: 0: args),
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
    self._save_model(epoch=epoch, logs=logs)
0: 0:     callbacks.on_epoch_end(epoch, epoch_logs)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
    self.model.save(filepath, overwrite=True, options=self._options)
0: 0:     callback.on_epoch_end(epoch, logs)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
0: 0:     self._save_model(epoch=epoch, logs=logs)
  File "/apps/applications/tensorflo0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
0: 0:     self.model.save(filepath, overwrite=True, options=self._options)
w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
    hdf5_format.save_model_to_hdf5(
0: 0:     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
0: 0:   File "/apps/applications/tensorflo    save_weights_to_hdf5_group(model_weights_group, model_layers)

0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
0: 0: w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
    weight_values = K.batch_get_value(weights)
0: 0:     hdf5_format.save_model_to_hdf5(
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
    return target(*args, **kwargs)
0: 0:     save_weights_to_hdf5_group(model_weights_group, model_layers)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
    return [x.numpy() for x in tensors]
0: 0:     weight_values = K.batch_get_value(weights)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:     return target(*args, **kwargs)
s/backend.py", line 3518, in <listcomp>
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
    return [x.numpy() for x in tensors]
0: 0:     return [x.numpy() for x in tensors]
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera    return self.read_value().numpy()

0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0: 0: s/backend.py", line 3518, in <listcomp>
    return array_ops.identity(self._get())
0: 0:     return [x.numpy() for x in tensors]
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
    return self._get_cross_replica()
0: 0:     return self.read_value().numpy()
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
    return self._distribute_strategy.reduce(
0: 0:     return array_ops.identity(self._get())
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
    return self._extended._reduce(reduce_op, value)  # pylint: disable=pro0: 
    return self._get_cross_replica()
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
tected-access
0: 0:     return self._distribute_strategy.reduce(
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
    return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
0: 0:     return self._extended._reduce(reduce_op, value)  # pylint: disable=pro  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to

0:     return self._reduce_to(reduce_op, value, destinations, experimental_hints)
0: 0: tected-access
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
    return self._get_cross_device_ops(value).reduce(
0: 0:     return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to
    return self.reduce_implementation(reduce_op, per_replica_value,
0: 0:     return self._reduce_to(reduce_op, value, destinations, experimental_hints)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
0: 0:     return self._get_cross_device_ops(value).reduce(
ne 983, in reduce_implementation
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
0: 0:     return self.reduce_implementation(reduce_op, per_replica_value,
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,

0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
0: 0: ne 983, in reduce_implementation
    value[i] = v / self._group_size
0: 0:     all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
    return func(x, y, name=name)
0: 0:     dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
    return target(*args, **kwargs)
0: 0:     value[i] = v / self._group_size
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
0: 0:     return func(x, y, name=name)
v
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
    return _truediv_python3(x, y, name)
0: 0:     return target(*args, **kwargs)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi    return gen_math_ops.real_div(x, y, name=name)

0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
0: 0: v
    _ops.raise_from_not_ok_status(e, name)
0: 0:     return _truediv_python3(x, y, name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
    six.raise_from(core._status_to_exception(e.code, message), None)
0: 0:     return gen_math_ops.real_div(x, y, name=name)
  File "<string>", line 3, in raise_from
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
tensorflow.python.framework.errors_impl.OutOfRangeError: [_Derived_]End of sequence
0: 0:     _ops.raise_from_not_ok_status(e, name)
	 [[{{node cond_3/else/_30/cond_3/IteratorGetNext}}]]
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
	 [[div_no_nan_1/allreduce/CollectiveReduce/_44]] [Op:RealDiv]
0:     six.raise_from(core._status_to_exception(e.code, message), None)
0:   File "<string>", line 3, in raise_from
0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
0: Traceback (most recent call last):
0:   File "train.tensorflow.distributed.py", line 131, in <module>
0:     main()
0:   File "train.tensorflow.distributed.py", line 108, in main
0:     hist = model.fit(train_dataset,
0: 0: Traceback (most recent call last):
0: 0:   File "train.tensorflow.distributed.py", line 131, in <module>
0:     main()
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
Traceback (most recent call last):
0:   File "train.tensorflow.distributed.py", line 108, in main
0: 0: 0:     hist = model.fit(train_dataset,
    return dc.run_distribute_coordinator(
  File "train.tensorflow.distributed.py", line 131, in <module>
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
0:     main()
0: 0: 0: Traceback (most recent call last):
0:     return dc.run_distribute_coordinator(
    return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
Traceback (most recent call last):
0:   File "train.tensorflow.distributed.py", line 108, in main
0: 0: 0:   File "train.tensorflow.distributed.py", line 131, in <module>
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
  File "train.tensorflow.distributed.py", line 131, in <module>
0:     hist = model.fit(train_dataset,
0: 0: 0:     main()
0:     return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
    return worker_fn(strategy)
    main()
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
0: 0: 0:   File "train.tensorflow.distributed.py", line 108, in main
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
  File "train.tensorflow.distributed.py", line 108, in main
0:     return dc.run_distribute_coordinator(
0: 0: 0:     hist = model.fit(train_dataset,
0:     return worker_fn(strategy)
    lambda _: method(self, *args, **kw    hist = model.fit(train_dataset,
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
0: 
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
0: 0: Traceback (most recent call last):
    return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
0: 0: args),
    return dc.run_distribute_coordinator(
0: 0:     lambda _: method(self, *args, **kw    return dc.run_distribute_coordinator(
0: 0:   File "train.tensorflow.distributed.py", line 131, in <module>
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker

0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator
0: 0: 0:     main()
    return worker_fn(strategy)
0:     callbacks.on_epoch_end(epoch, epoch_logs)
args),
    return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
0: 0:     return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
0: 0: 0:   File "train.tensorflow.distributed.py", line 108, in main
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
0: 0: 0:     hist = model.fit(train_dataset,
    lambda _: method(self, *args, **kw0:     callback.on_epoch_end(epoch, logs)
    callbacks.on_epoch_end(epoch, epoch_logs)
    return worker_fn(strategy)
0: 
    return worker_fn(strategy)
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 114, in _method_wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
args),
0: 0: 0:     return dc.run_distribute_coordinator(
0: 0:     self._save_model(epoch=epoch, logs=logs)
    callback.on_epoch_end(epoch, logs)
    lambda _: method(self, *args, **kw0:     lambda _: method(self, *args, **kw  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
0: 0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 859, in run_distribute_coordinator

0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
0: 0:     callbacks.on_epoch_end(epoch, epoch_logs)
0: 0: 0:     return _run_single_worker(worker_fn, strategy, cluster_spec, task_type,
args),
0: args),
    self.model.save(filepath, overwrite=True, options=self._options)
    self._save_model(epoch=epoch, logs=logs)
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_coordinator.py", line 360, in _run_single_worker
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
0: 0:     callback.on_epoch_end(epoch, logs)
0: 0: 0:     return worker_fn(strategy)
    callbacks.on_epoch_end(epoch, epoch_logs)
0:     callbacks.on_epoch_end(epoch, epoch_logs)
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
    self.model.save(filepath, overwrite=True, options=self._options)
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 115, in <lambda>
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
  File "/apps/applications/tensorflo  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
0: 0:     self._save_model(epoch=epoch, logs=logs)
0: 
0:     lambda _: method(self, *args, **kw    callback.on_epoch_end(epoch, logs)
0:     callback.on_epoch_end(epoch, logs)
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
0: 
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
0: 0: w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
  File "/apps/applications/tensorflo0: 0: args),
    self.model.save(filepath, overwrite=True, options=self._options)
0: 
    hdf5_format.save_model_to_hdf5(
    self._save_model(epoch=epoch, logs=logs)
0: 0:     self._save_model(epoch=epoch, logs=logs)
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
0: 0: 0:     callbacks.on_epoch_end(epoch, epoch_logs)
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
0:     save_weights_to_hdf5_group(model_weights_group, model_layers)
    hdf5_format.save_model_to_hdf5(
    self.model.save(filepath, overwrite=True, options=self._options)
0: 0:     self.model.save(filepath, overwrite=True, options=self._options)
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
  File "/apps/applications/tensorflo0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
0: 0: 0:     callback.on_epoch_end(epoch, logs)
0: 0:     weight_values = K.batch_get_value(weights)
    save_weights_to_hdf5_group(model_weights_group, model_layers)
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
0:     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
  File "/apps/applications/tensorflo0:   File "/apps/applications/tensorflo    hdf5_format.save_model_to_hdf5(
0: 0: 
    self._save_model(epoch=epoch, logs=logs)

0:     return target(*args, **kwargs)
    weight_values = K.batch_get_value(weights)
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1313, in _save_model
w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
0: w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:     save_weights_to_hdf5_group(model_weights_group, model_layers)
0: 0: 0:     self.model.save(filepath, overwrite=True, options=self._options)
    hdf5_format.save_model_to_hdf5(
0:     hdf5_format.save_model_to_hdf5(
    return [x.numpy() for x in tensors]
    return target(*args, **kwargs)
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1978, in save
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
0: 0:     weight_values = K.batch_get_value(weights)
0: 
0:     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
    save_weights_to_hdf5_group(model_weights_group, model_layers)
0:     save_weights_to_hdf5_group(model_weights_group, model_layers)
    return [x.numpy() for x in tensors]
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0: s/backend.py", line 3518, in <listcomp>
  File "/apps/applications/tensorflo  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera0: 
0:     return target(*args, **kwargs)
0: 
    return [x.numpy() for x in tensors]
    weight_values = K.batch_get_value(weights)
0: 0:     weight_values = K.batch_get_value(weights)
0: 0: 0: w/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py", line 130, in save_model
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
s/backend.py", line 3518, in <listcomp>
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0: 0:     hdf5_format.save_model_to_hdf5(
    return [x.numpy() for x in tensors]
0:     return self.read_value().numpy()
    return [x.numpy() for x in tensors]
    return target(*args, **kwargs)
0: 0:     return target(*args, **kwargs)
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
0:     return self.read_value().numpy()
0:     save_weights_to_hdf5_group(model_weights_group, model_layers)
0: 0:     return array_ops.identity(self._get())
0:     return [x.numpy() for x in tensors]
0:     return [x.numpy() for x in tensors]
s/backend.py", line 3518, in <listcomp>
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 636, in save_weights_to_hdf5_group
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera    return [x.numpy() for x in tensors]
0:     return array_ops.identity(self._get())

    weight_values = K.batch_get_value(weights)

0:     return self._get_cross_replica()
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
s/backend.py", line 3518, in <listcomp>
0: s/backend.py", line 3518, in <listcomp>
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
0: 0: 0:     return self.read_value().numpy()
0: 0:     return self._get_cross_replica()
    return target(*args, **kwargs)
    return [x.numpy() for x in tensors]
0:     return [x.numpy() for x in tensors]
    return self._distribute_strategy.reduce(
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py", line 3518, in batch_get_value
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
0: 0: 0:     return array_ops.identity(self._get())
0: 0:     return self._distribute_strategy.reduce(
    return [x.numpy() for x in tensors]
    return self.read_value().numpy()
0:     return self.read_value().numpy()
    return self._extended._reduce(reduce_op, value)  # pylint: disable=pro0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/kera  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0: 0: 
0:     return self._get_cross_replica()
0:     return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access
    return array_ops.identity(self._get())
0: 0:     return array_ops.identity(self._get())

0: 0: s/backend.py", line 3518, in <listcomp>
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
0: tected-access
    return self._get_cross_replica()
    return [x.numpy() for x in tensors]
    return self._distribute_strategy.reduce(
0:     return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
0: 0: 0: 0:     return self._get_cross_replica()
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 662, in numpy
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to
0: 0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
0:     return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
    return self._distribute_strategy.reduce(
    return self.read_value().numpy()
    return self._extended._reduce(reduce_op, value)  # pylint: disable=pro0:     return self._reduce_to(reduce_op, value, destinations, experimental_hints)
0: 0: 0: 
    return self._distribute_strategy.reduce(
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 653, in read_value
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
tected-access
0:     return self._reduce_to(reduce_op, value, destinations, experimental_hints)
    return self._extended._reduce(reduce_op, value)  # pylint: disable=pro    return array_ops.identity(self._get())
0: 0:     return self._get_cross_device_ops(value).reduce(
0: 
0:     return self._extended._reduce(reduce_op, value)  # pylint: disable=pro  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 634, in _get
0: 
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
0: 0: tected-access
    return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
0: 0:     return self._get_cross_device_ops(value).reduce(
    return self._get_cross_replica()
0: 0: tected-access
    return self.reduce_implementation(reduce_op, per_replica_value,
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/values.py", line 1068, in _get_cross_replica
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li0: 0:     return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
    return self._reduce_to(reduce_op, value, destinations, experimental_hints)
0: 
    return self.reduce_implementation(reduce_op, per_replica_value,
    return self._distribute_strategy.reduce(
0: 0:     return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 983, in reduce_implementation
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1262, in reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to

0: 0:     return self._reduce_to(reduce_op, value, destinations, experimental_hints)
    return self._get_cross_device_ops(value).reduce(
0:     all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
0:     return self._extended._reduce(reduce_op, value)  # pylint: disable=pro0: 0:     return self._reduce_to(reduce_op, value, destinations, experimental_hints)
0: ne 983, in reduce_implementation

  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
0: 0: 0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
0:     all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
    return self._get_cross_device_ops(value).reduce(
tected-access
    return self.reduce_implementation(reduce_op, per_replica_value,
0:     dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
0: 0: 0: 0:     return self._get_cross_device_ops(value).reduce(
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2166, in _reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
0: 0: 0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
0:     dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
    return self.reduce_implementation(reduce_op, per_replica_value,
    return self._local_results(self.reduce_to(reduce_op, value, dst))[0]
0: 0:     value[i] = v / self._group_size
0: 0: 0:     return self.reduce_implementation(reduce_op, per_replica_value,
ne 983, in reduce_implementation
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2194, in reduce_to
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
0: 
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
0:     value[i] = v / self._group_size
    return self._reduce_to(reduce_op, value, destinations, experimental_hints)
0: 
0:     return func(x, y, name=name)
0: 0: ne 983, in reduce_implementation
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 586, in _reduce_to
0: 0: ne 983, in reduce_implementation
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:     all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
0: 0:     return func(x, y, name=name)
    return self._get_cross_device_ops(value).reduce(
0: 0:     all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
    return target(*args, **kwargs)
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 269, in reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi0: 0:     dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
0:     value[i] = v / self._group_size
0:     value[i] = v / self._group_size
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
    return func(x, y, name=name)
0: 0:     return func(x, y, name=name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
    return target(*args, **kwargs)
0: 0:     return target(*args, **kwargs)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi0: 
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi
0: v
0: 0:     return _truediv_python3(x, y, name)
v
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
    return _truediv_python3(x, y, name)
0: 0:     return gen_math_ops.real_div(x, y, name=name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
    return gen_math_ops.real_div(x, y, name=name)
0: 0:     _ops.raise_from_not_ok_status(e, name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
    _ops.raise_from_not_ok_status(e, name)
0: 0:     six.raise_from(core._status_to_exception(e.code, message), None)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
0: 0:   File "<string>", line 3, in raise_from
    six.raise_from(core._status_to_exception(e.code, message), None)
0: 0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
  File "<string>", line 3, in raise_from
0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
0:     dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
0:     value[i] = v / self._group_size
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
0:     return func(x, y, name=name)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0:     return target(*args, **kwargs)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi

0: v
0: 0:     return _truediv_python3(x, y, name)
v
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
    return _truediv_python3(x, y, name)
0: 0:     return gen_math_ops.real_div(x, y, name=name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
    return gen_math_ops.real_div(x, y, name=name)
0: 0:     _ops.raise_from_not_ok_status(e, name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
    _ops.raise_from_not_ok_status(e, name)
0: 0:     six.raise_from(core._status_to_exception(e.code, message), None)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
0: 0:   File "<string>", line 3, in raise_from
    six.raise_from(core._status_to_exception(e.code, message), None)
0: 0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
  File "<string>", line 3, in raise_from
0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
    return target(*args, **kwargs)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi
    return self.reduce_implementation(reduce_op, per_replica_value,
0: 0: v
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", li0: 
    return _truediv_python3(x, y, name)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
0: 0:     return gen_math_ops.real_div(x, y, name=name)
ne 983, in reduce_implementation
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value],
0: 0:     _ops.raise_from_not_ok_status(e, name)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1036, in _batch_all_reduce
0: 0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values,
0: 0:     six.raise_from(core._status_to_exception(e.code, message), None)
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py", line 1119, in _do_batch_all_reduce_dense
0: 0:   File "<string>", line 3, in raise_from
    value[i] = v / self._group_size
0: 0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
  File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1125, in binary_op_wrapper
0:     return func(x, y, name=name)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
0:     return target(*args, **kwargs)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1297, in truedi
0: v
0:     return _truediv_python3(x, y, name)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 1236, in _truediv_python3
0:     return gen_math_ops.real_div(x, y, name=name)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py", line 7443, in real_div
0:     _ops.raise_from_not_ok_status(e, name)
0:   File "/apps/applications/tensorflow/2.3.0/gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 6843, in raise_from_not_ok_status
0:     six.raise_from(core._status_to_exception(e.code, message), None)
0:   File "<string>", line 3, in raise_from
0: tensorflow.python.framework.errors_impl.CancelledError: RPC Request was cancelled [Op:RealDiv]
0: 2021-02-16 23:02:00.830532: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.844889: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.863951: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.870862: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.891810: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.897312: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.903483: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:00.914016: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
0: 	 [[{{node PyFunc}}]]
0: 2021-02-16 23:02:02.661507: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.709747: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.765577: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.770960: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.781368: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.814060: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.853141: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
0: 2021-02-16 23:02:02.882336: W tensorflow/core/common_runtime/eager/context.cc:566] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
srun: error: gpu25: task 0: Exited with exit code 1
srun: Terminating job step 1096234.3
srun: error: gpu29: task 0: Exited with exit code 1
srun: Terminating job step 1096234.5
srun: error: gpu23: task 0: Exited with exit code 1
srun: Terminating job step 1096234.0
srun: error: gpu27: task 0: Exited with exit code 1
srun: Terminating job step 1096234.4
srun: error: gpu28: task 0: Exited with exit code 1
srun: Terminating job step 1096234.7
srun: error: gpu26: task 0: Exited with exit code 1
srun: Terminating job step 1096234.2
srun: error: gpu30: task 0: Exited with exit code 1
srun: Terminating job step 1096234.6
srun: error: gpu24: task 0: Exited with exit code 1
srun: Terminating job step 1096234.1
